{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generating spectrograms from audio files (and some cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script creates spectrograms from a list of input audio files.\n",
    "#### The following minimal structure and files are required in the project directory:\n",
    "\n",
    "    ├── audio\n",
    "    │   ├── call_1.wav     <- call files (Mono, not stereo sound!)\n",
    "    │   ├── call_2.wav     <- \n",
    "    │   ├── call_3.wav     <- \n",
    "    │   └── ...            <- \n",
    "    ├── data               <- empty directory for output files      \n",
    "        ├── info_file.csv  <- A \";\"-separated csv file containing metadata about the calls\n",
    "\n",
    "#### The following structure is required for info_file.csv:\n",
    "\n",
    "(must contain at least the two columns: \"filename\" and \"label\"). If labels are completely unknown, there should still be a label column with some NA identifiers (e..g \"unknown\")\n",
    "\n",
    "    | filename   | label   | ...    |  .... \n",
    "    -----------------------------------------\n",
    "    | call_1.wav | alarm   |  ...   |  ....   \n",
    "    | call_2.wav | contact |  ...   |  ....  \n",
    "    | ...        |  ...    |  ...   |  ....   \n",
    "\n",
    "#### The following files are generated in this script:\n",
    "\n",
    "    ├── data               \n",
    "    │   ├── df.pkl <- pickled pandas dataframe with metadata, raw_audio and spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements, constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "import umap\n",
    "import sys \n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from functions.audio_functions import generate_mel_spectrogram, read_wavfile\n",
    "from functions.preprocessing_functions import calc_zscore, pad_spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDPASS_FILTER = False  # should bandpass-filtered spectrograms be generated?\n",
    "MEDIAN_SUB = False  # should median-subtracted spectrograms be generated (reduce impulse noise)?\n",
    "STRETCH = False    # should time-stretched spectrograms be generated (all stretched to max. duration in dataset)?\n",
    "\n",
    "LABEL_COL = \"label\"     # name of column that contains labels\n",
    "NA_DESCRIPTORS = [0, np.nan, \"NA\", \"na\", \"not available\", # values that indicate \"no label\"\n",
    "                  \"None\", \"Unknown\", \"unknown\", None, \"\"]     # add your NA descriptor if not yet in list\n",
    "                                                     \n",
    "NEW_NA_INDICATOR = \"unknown\" # all vocalizations without label will be relabelled as \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_DIR = str(Path(os.getcwd()).parents[0])            # project directory\n",
    "AUDIO_IN = os.path.join(os.path.sep, P_DIR, 'audio') # --> audio directory, contains audio (.wav) files\n",
    "DATA = os.path.join(os.path.sep, P_DIR, 'data')      # --> empty data directory, output files will be put here\n",
    "\n",
    "\n",
    "# Check if directories are present\n",
    "\n",
    "if not os.path.isdir(AUDIO_IN):\n",
    "    print(\"No audio directory found\")\n",
    "\n",
    "if not os.path.isdir(DATA):\n",
    "    os.mkdir(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.path.sep, DATA, 'info_file.csv'), sep=\";\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>indv</th>\n",
       "      <th>ori_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...</td>\n",
       "      <td>al</td>\n",
       "      <td>HMB</td>\n",
       "      <td>ALARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...</td>\n",
       "      <td>al</td>\n",
       "      <td>HMB</td>\n",
       "      <td>ALARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...</td>\n",
       "      <td>al</td>\n",
       "      <td>HMB</td>\n",
       "      <td>ALARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...</td>\n",
       "      <td>al</td>\n",
       "      <td>HMB</td>\n",
       "      <td>ALARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...</td>\n",
       "      <td>al</td>\n",
       "      <td>HMB</td>\n",
       "      <td>ALARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18941</th>\n",
       "      <td>HM_VHMF001_HTB_R20_20190707-20190719_file_7_(2...</td>\n",
       "      <td>cc</td>\n",
       "      <td>VHMF001</td>\n",
       "      <td>cc $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX2...</td>\n",
       "      <td>cc</td>\n",
       "      <td>RT</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>HM_VHMM023_MBLS_R02_20190707-20190719_file_10_...</td>\n",
       "      <td>cc</td>\n",
       "      <td>VHMM023</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29707</th>\n",
       "      <td>HM_VHMM014_LSTB_R19_20190707-20190719_file_8_(...</td>\n",
       "      <td>cc</td>\n",
       "      <td>VHMM014</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32956</th>\n",
       "      <td>HM_VHMM023_MBLS_R02_20190707-20190719_file_10_...</td>\n",
       "      <td>cc</td>\n",
       "      <td>VHMM023</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6430 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename label     indv  \\\n",
       "26     HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...    al      HMB   \n",
       "27     HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...    al      HMB   \n",
       "28     HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...    al      HMB   \n",
       "29     HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...    al      HMB   \n",
       "30     HM_HMB_R11_AUDIO_file_4_(2017_08_23-06_44_59)_...    al      HMB   \n",
       "...                                                  ...   ...      ...   \n",
       "18941  HM_VHMF001_HTB_R20_20190707-20190719_file_7_(2...    cc  VHMF001   \n",
       "13340  HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX2...    cc       RT   \n",
       "32998  HM_VHMM023_MBLS_R02_20190707-20190719_file_10_...    cc  VHMM023   \n",
       "29707  HM_VHMM014_LSTB_R19_20190707-20190719_file_8_(...    cc  VHMM014   \n",
       "32956  HM_VHMM023_MBLS_R02_20190707-20190719_file_10_...    cc  VHMM023   \n",
       "\n",
       "      ori_label  \n",
       "26        ALARM  \n",
       "27        ALARM  \n",
       "28        ALARM  \n",
       "29        ALARM  \n",
       "30        ALARM  \n",
       "...         ...  \n",
       "18941      cc $  \n",
       "13340        CC  \n",
       "32998        cc  \n",
       "29707        cc  \n",
       "32956      cc    \n",
       "\n",
       "[6430 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all audio files are in AUDIO_IN directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofiles = df['filename'].values\n",
    "files_in_audio_directory = os.listdir(AUDIO_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files = list(set(audiofiles) - set(files_in_audio_directory))\n",
    "if len(missing_files)>0:\n",
    "    print(len(missing_files), \"files with no matching audio in audio folder: \", missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filepaths = [os.path.join(os.path.sep, AUDIO_IN,x) for x in audiofiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding audio (and samplerate) to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_audio,samplerate_hz = map(list,zip(*[read_wavfile(x) for x in audio_filepaths]))\n",
    "\n",
    "df['raw_audio'] = raw_audio\n",
    "df['samplerate_hz'] = samplerate_hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped  0  rows due to missing/failed audio\n"
     ]
    }
   ],
   "source": [
    "# Removing NA rows\n",
    "\n",
    "nrows = df.shape[0]\n",
    "df.dropna(subset=['raw_audio'], inplace=True)\n",
    "print(\"Dropped \", nrows-df.shape[0], \" rows due to missing/failed audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing very long calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's advisable to remove very long calls, as all calls will be zero-padded to the maximum duration in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract duration of calls\n",
    "df['duration_s'] = [x.shape[0] for x in df['raw_audio']]/df['samplerate_hz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Can be helpful to plot the distribution to find a good cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#n, bins, patches = plt.hist(df['duration_s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, dataset was already cleaned and all calls were between 0-0.5s, so no need to remove long calls. Set MIN_DUR and MAX_DUR to values that make sense for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DUR = 0  # --> minimum duration of calls in seconds\n",
    "MAX_DUR = 0.5 # --> maximum duration of calls in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped  0 rows below  0 s (min_dur)\n",
      "Dropped  0 rows above  0.5 s (max_dur)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropped \", df.loc[df['duration_s']<MIN_DUR,:].shape[0], \"rows below \", MIN_DUR, \"s (min_dur)\")\n",
    "df = df.loc[df['duration_s']>=MIN_DUR,:]\n",
    "print(\"Dropped \", df.loc[df['duration_s']>MAX_DUR,:].shape[0], \"rows above \", MAX_DUR, \"s (max_dur)\")\n",
    "df = df.loc[df['duration_s']<=MAX_DUR,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate mel-spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, spectrograms are generated from audio files via short-time fourier transformation. Spectrograms capture the frequency components of a signal over time. A spectrogram is a 2D matrix, where each value represents the signal intensity in a specific time (columns) and frequency bin (row). In this case, the frequency axis of the spectrograms are also Mel-transformed (a logarithmic scale) and signal intensity is expressed on a Decibel scale.\n",
    "\n",
    "The following parameters define how the spectrograms are computed. You can leave this as default or choose your own parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Set spectrogramming parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MELS = 40 # --> number of mel bins (usually 20-40)\n",
    "            # The frequency bins are transformed to this number of logarithmically spaced mel bins.\n",
    "\n",
    "FFT_WIN = 0.03 # --> length of audio chunk when applying STFT in seconds\n",
    "               # FFT_WIN * samplerate = number of audio datapoints that go in one fft (=n_fft)\n",
    "\n",
    "FFT_HOP = FFT_WIN/8 # --> hop_length in seconds\n",
    "                    # FFT_HOP * samplerate = n of audio datapoints between successive ffts (=hop_length)\n",
    "\n",
    "WINDOW = 'hann' # --> name of window function\n",
    "                # each frame of audio is windowed by a window function. We use the window function 'hanning',  \n",
    "\n",
    "FMIN = 0 # --> lower bound for frequency (in Hz) when generating Mel filterbank\n",
    "FMAX = int(np.min(df['samplerate_hz'])/2) #--> upper bound for frequency (in Hz) when generating Mel filterbank\n",
    "                                                 # this is set to 0.5 times the samplerate (-> Nyquist rule)\n",
    "                                                 # If input files have different samplerates, the lowest samplerate is used\n",
    "                                                 # to ensure all spectrograms have the same frequency resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save these parameters as they will be needed for all subsequent scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['N_MELS = '+str(N_MELS),\n",
    "         'FFT_WIN = '+str(FFT_WIN),\n",
    "         'FFT_HOP = '+str(FFT_HOP),\n",
    "         'WINDOW = \"'+str(WINDOW)+'\"',\n",
    "         'FMIN = '+str(FMIN),\n",
    "         'FMAX = '+str(FMAX)]\n",
    "\n",
    "with open(os.path.join(os.path.sep, P_DIR, 'spec_params.py'), 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = df.apply(lambda row: generate_mel_spectrogram(row['raw_audio'],\n",
    "                                                                    row['samplerate_hz'],\n",
    "                                                                    N_MELS,\n",
    "                                                                    WINDOW,\n",
    "                                                                    FFT_WIN,\n",
    "                                                                    FFT_HOP,\n",
    "                                                                    FMAX), \n",
    "                               axis=1)\n",
    "\n",
    "\n",
    "df['spectrograms'] = spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped  0  rows due to failed spectrogram generation\n"
     ]
    }
   ],
   "source": [
    "# Removing NA rows\n",
    "\n",
    "nrows = df.shape[0]\n",
    "df.dropna(subset=['spectrograms'], inplace=True)\n",
    "print(\"Dropped \", nrows-df.shape[0], \" rows due to failed spectrogram generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional: 5. Generate denoised files (median subtraction):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEDIAN_SUB:\n",
    "    df['denoised_spectrograms'] = [(spectrogram - np.median(spectrogram, axis=0)) for spectrogram in df['spectrograms']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional : 6. Generate denoised files (bandpass filter):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BANDPASS_FILTER:\n",
    "    from scipy.signal import butter, lfilter\n",
    "\n",
    "    # Bandpass filters for calculating audio intensity\n",
    "    LOWCUT = 300.0\n",
    "    HIGHCUT = 3000.0\n",
    "\n",
    "    # Butter bandpass filter implementation:\n",
    "    # from https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "\n",
    "    def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "\n",
    "    def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "    \n",
    "    df['filtered_audio'] = df.apply(lambda row: butter_bandpass_filter(row['raw_audio'], \n",
    "                                                                   LOWCUT, \n",
    "                                                                   HIGHCUT, \n",
    "                                                                   row['samplerate_hz'],\n",
    "                                                                   order=6),\n",
    "                               axis=1)\n",
    "\n",
    "    filtered_spectrograms = df.apply(lambda row: generate_mel_spectrogram(row['filtered_audio'],\n",
    "                                                                        row['samplerate_hz'],\n",
    "                                                                        N_MELS,\n",
    "                                                                        WINDOW,\n",
    "                                                                        FFT_WIN,\n",
    "                                                                        FFT_HOP,\n",
    "                                                                        FMAX), \n",
    "                                   axis=1)\n",
    "\n",
    "\n",
    "    df['filtered_spectrograms'] = filtered_spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional: 7. Generate stretched spectrograms (all stretched to equal length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STRETCH:\n",
    "    MAX_DURATION = np.max(df['duration_s'])\n",
    "\n",
    "    df['stretched_spectrograms'] = df.apply(lambda row: generate_stretched_mel_spectrogram(row['raw_audio'],\n",
    "                                                                                           row['samplerate_hz'],\n",
    "                                                                                           row['duration_s'],\n",
    "                                                                                           N_MELS,\n",
    "                                                                                           WINDOW,\n",
    "                                                                                           FFT_WIN,\n",
    "                                                                                           FFT_HOP,\n",
    "                                                                                           MAX_DURATION),\n",
    "                                            axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clean labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all labels into strings and label all calls without label as \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_label'] = df[LABEL_COL] #  original labels are saved in \"original_label\" column\n",
    "\n",
    "df['label'] = [\"unknown\" if x in NA_DESCRIPTORS else x for x in df[LABEL_COL]]  # \"unknown\" for all NA labels\n",
    "labels = df['label'].fillna(NEW_NA_INDICATOR) # double-check\n",
    "df['label'] = labels.astype(str) # transform to strings and save in df as \"label\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.path.join(os.path.sep, DATA, 'df.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
